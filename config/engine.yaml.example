# AI Gateway Engine config for Docker runtime (file-based)

server:
  host: "0.0.0.0"
  port: 8090
  workers: 4

business_api:
  # Points to backend's internal engine server
  base_url: "http://ai-backend:8081"
  timeout: "5s"
  retry_attempts: 3

cache:
  type: "memory"
  ttl: "5m"
  max_size: 10000

proxy:
  timeout: "30s"
  max_connections: 500
  keep_alive: true
  retry_attempts: 3
